#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GFWæ•°æ®å¿«é€Ÿä¸‹è½½å™¨ - æ”¯æŒæ–­ç‚¹ç»­ä¼ ã€VPNä»£ç†ã€å¤šçº¿ç¨‹ä¸‹è½½
ç›®çš„ï¼šé’ˆå¯¹å¤§æ–‡ä»¶æä¾›é«˜æ•ˆçš„ä¸‹è½½è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œä»£ç†è®¾ç½®
ä½œè€…ï¼šé”å¤šå® (ruiduobao)
"""

import requests
import os
import time
import threading
from datetime import datetime
import json
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse

class FastDownloader:
    def __init__(self, use_proxy=True, proxy_port=7890, max_workers=8, chunk_size=1024*1024):
        """
        åˆå§‹åŒ–å¿«é€Ÿä¸‹è½½å™¨
        
        Args:
            use_proxy (bool): æ˜¯å¦ä½¿ç”¨VPNä»£ç†
            proxy_port (int): ä»£ç†ç«¯å£å·
            max_workers (int): æœ€å¤§çº¿ç¨‹æ•°
            chunk_size (int): æ¯ä¸ªçº¿ç¨‹ä¸‹è½½çš„å—å¤§å°(å­—èŠ‚)
        """
        self.use_proxy = use_proxy
        self.proxy_port = proxy_port
        self.max_workers = max_workers
        self.chunk_size = chunk_size
        self.session = requests.Session()
        
        # è®¾ç½®ä»£ç†
        if self.use_proxy:
            proxies = {
                'http': f'http://127.0.0.1:{proxy_port}',
                'https': f'http://127.0.0.1:{proxy_port}'
            }
            self.session.proxies.update(proxies)
            print(f"ğŸŒ å·²é…ç½®VPNä»£ç†: 127.0.0.1:{proxy_port}")
        
        # è®¾ç½®è¯·æ±‚å¤´
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—è®°å½•"""
        log_filename = f"download_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_filename, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_filename}")
    
    def get_file_size(self, url, headers=None):
        """è·å–è¿œç¨‹æ–‡ä»¶å¤§å°"""
        try:
            response = self.session.head(url, headers=headers or {})
            if response.status_code == 200:
                return int(response.headers.get('content-length', 0))
            else:
                # å¦‚æœHEADè¯·æ±‚å¤±è´¥ï¼Œå°è¯•GETè¯·æ±‚è·å–éƒ¨åˆ†å†…å®¹
                response = self.session.get(url, headers=headers or {}, stream=True)
                size = int(response.headers.get('content-length', 0))
                response.close()
                return size
        except Exception as e:
            self.logger.error(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥: {str(e)}")
            return 0
    
    def download_chunk(self, url, headers, start, end, filename, chunk_id):
        """ä¸‹è½½æ–‡ä»¶çš„ä¸€ä¸ªå—"""
        chunk_headers = headers.copy() if headers else {}
        chunk_headers['Range'] = f'bytes={start}-{end}'
        
        temp_filename = f"{filename}.part{chunk_id}"
        
        try:
            response = self.session.get(url, headers=chunk_headers, stream=True)
            
            if response.status_code in [206, 200]:  # 206: Partial Content, 200: OK
                with open(temp_filename, 'wb') as f:
                    downloaded = 0
                    for data in response.iter_content(chunk_size=8192):
                        if data:
                            f.write(data)
                            downloaded += len(data)
                
                self.logger.info(f"å— {chunk_id} ä¸‹è½½å®Œæˆ: {downloaded} å­—èŠ‚")
                return True, chunk_id, downloaded
            else:
                self.logger.error(f"å— {chunk_id} ä¸‹è½½å¤±è´¥: HTTP {response.status_code}")
                return False, chunk_id, 0
                
        except Exception as e:
            self.logger.error(f"å— {chunk_id} ä¸‹è½½å¼‚å¸¸: {str(e)}")
            return False, chunk_id, 0
    
    def merge_chunks(self, filename, total_chunks):
        """åˆå¹¶æ‰€æœ‰ä¸‹è½½çš„å—"""
        print("ğŸ”„ æ­£åœ¨åˆå¹¶æ–‡ä»¶å—...")
        
        with open(filename, 'wb') as output_file:
            for i in range(total_chunks):
                chunk_filename = f"{filename}.part{i}"
                if os.path.exists(chunk_filename):
                    with open(chunk_filename, 'rb') as chunk_file:
                        output_file.write(chunk_file.read())
                    os.remove(chunk_filename)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                else:
                    self.logger.error(f"ç¼ºå°‘æ–‡ä»¶å—: {chunk_filename}")
                    return False
        
        print("âœ… æ–‡ä»¶åˆå¹¶å®Œæˆ!")
        return True
    
    def resume_download(self, filename):
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥æ–­ç‚¹ç»­ä¼ """
        if os.path.exists(filename):
            existing_size = os.path.getsize(filename)
            print(f"ğŸ”„ å‘ç°å·²å­˜åœ¨æ–‡ä»¶ï¼Œå¤§å°: {existing_size / (1024*1024):.2f} MB")
            return existing_size
        return 0
    
    def download_file(self, url, filename, headers=None, resume=True):
        """
        å¤šçº¿ç¨‹ä¸‹è½½æ–‡ä»¶ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
        
        Args:
            url (str): ä¸‹è½½é“¾æ¥
            filename (str): ä¿å­˜æ–‡ä»¶å
            headers (dict): è¯·æ±‚å¤´
            resume (bool): æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
        """
        print(f"ğŸš€ å¼€å§‹ä¸‹è½½: {filename}")
        print(f"ğŸ”— ä¸‹è½½é“¾æ¥: {url}")
        
        # æ£€æŸ¥æ–­ç‚¹ç»­ä¼ 
        existing_size = 0
        if resume:
            existing_size = self.resume_download(filename)
        
        # è·å–æ–‡ä»¶æ€»å¤§å°
        total_size = self.get_file_size(url, headers)
        if total_size == 0:
            print("âš ï¸  æ— æ³•è·å–æ–‡ä»¶å¤§å°ï¼Œå°è¯•å•çº¿ç¨‹ä¸‹è½½...")
            return self.single_thread_download(url, filename, headers, existing_size)
        
        print(f"ğŸ“Š æ–‡ä»¶æ€»å¤§å°: {total_size / (1024*1024):.2f} MB")
        
        # å¦‚æœæ–‡ä»¶å·²å®Œæ•´ä¸‹è½½
        if existing_size >= total_size:
            print("âœ… æ–‡ä»¶å·²å®Œæ•´ä¸‹è½½!")
            return True
        
        # è®¡ç®—éœ€è¦ä¸‹è½½çš„èŒƒå›´
        remaining_size = total_size - existing_size
        
        # è®¡ç®—çº¿ç¨‹æ•°å’Œæ¯ä¸ªçº¿ç¨‹çš„ä¸‹è½½èŒƒå›´
        if remaining_size < self.chunk_size:
            # æ–‡ä»¶å¤ªå°ï¼Œä½¿ç”¨å•çº¿ç¨‹
            num_threads = 1
        else:
            num_threads = min(self.max_workers, remaining_size // self.chunk_size + 1)
        
        chunk_size = remaining_size // num_threads
        
        print(f"ğŸ§µ ä½¿ç”¨ {num_threads} ä¸ªçº¿ç¨‹ä¸‹è½½")
        
        # åˆ›å»ºä¸‹è½½ä»»åŠ¡
        download_tasks = []
        for i in range(num_threads):
            start = existing_size + i * chunk_size
            if i == num_threads - 1:
                end = total_size - 1  # æœ€åä¸€ä¸ªçº¿ç¨‹ä¸‹è½½åˆ°æ–‡ä»¶æœ«å°¾
            else:
                end = start + chunk_size - 1
            
            download_tasks.append((start, end, i))
        
        # æ‰§è¡Œå¤šçº¿ç¨‹ä¸‹è½½
        start_time = time.time()
        completed_chunks = 0
        total_downloaded = existing_size
        
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            future_to_chunk = {
                executor.submit(self.download_chunk, url, headers, start, end, filename, chunk_id): chunk_id
                for start, end, chunk_id in download_tasks
            }
            
            for future in as_completed(future_to_chunk):
                success, chunk_id, downloaded = future.result()
                if success:
                    completed_chunks += 1
                    total_downloaded += downloaded
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    progress = (total_downloaded / total_size) * 100
                    elapsed_time = time.time() - start_time
                    speed = total_downloaded / elapsed_time / (1024*1024) if elapsed_time > 0 else 0
                    
                    print(f"\rğŸ“¥ ä¸‹è½½è¿›åº¦: {progress:.1f}% "
                          f"({total_downloaded/(1024*1024):.2f}/{total_size/(1024*1024):.2f} MB) "
                          f"é€Ÿåº¦: {speed:.2f} MB/s", end='', flush=True)
                else:
                    self.logger.error(f"å— {chunk_id} ä¸‹è½½å¤±è´¥")
        
        print()  # æ¢è¡Œ
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å—éƒ½ä¸‹è½½æˆåŠŸ
        if completed_chunks == num_threads:
            # åˆå¹¶æ–‡ä»¶å—
            if self.merge_chunks(filename, num_threads):
                elapsed_time = time.time() - start_time
                avg_speed = total_size / elapsed_time / (1024*1024) if elapsed_time > 0 else 0
                print(f"âœ… ä¸‹è½½å®Œæˆ! ç”¨æ—¶: {elapsed_time:.1f}ç§’, å¹³å‡é€Ÿåº¦: {avg_speed:.2f} MB/s")
                return True
            else:
                print("âŒ æ–‡ä»¶åˆå¹¶å¤±è´¥!")
                return False
        else:
            print(f"âŒ ä¸‹è½½å¤±è´¥! åªå®Œæˆäº† {completed_chunks}/{num_threads} ä¸ªå—")
            return False
    
    def single_thread_download(self, url, filename, headers=None, resume_size=0):
        """å•çº¿ç¨‹ä¸‹è½½ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        print("ğŸ“¥ ä½¿ç”¨å•çº¿ç¨‹ä¸‹è½½...")
        
        download_headers = headers.copy() if headers else {}
        if resume_size > 0:
            download_headers['Range'] = f'bytes={resume_size}-'
            mode = 'ab'  # è¿½åŠ æ¨¡å¼
        else:
            mode = 'wb'   # è¦†å†™æ¨¡å¼
        
        try:
            response = self.session.get(url, headers=download_headers, stream=True)
            
            if response.status_code in [200, 206]:
                total_size = int(response.headers.get('content-length', 0)) + resume_size
                downloaded = resume_size
                
                start_time = time.time()
                
                with open(filename, mode) as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                            
                            if total_size > 0:
                                progress = (downloaded / total_size) * 100
                                elapsed_time = time.time() - start_time
                                speed = (downloaded - resume_size) / elapsed_time / (1024*1024) if elapsed_time > 0 else 0
                                
                                print(f"\rğŸ“¥ ä¸‹è½½è¿›åº¦: {progress:.1f}% "
                                      f"({downloaded/(1024*1024):.2f}/{total_size/(1024*1024):.2f} MB) "
                                      f"é€Ÿåº¦: {speed:.2f} MB/s", end='', flush=True)
                
                print()
                print("âœ… å•çº¿ç¨‹ä¸‹è½½å®Œæˆ!")
                return True
            else:
                print(f"âŒ ä¸‹è½½å¤±è´¥: HTTP {response.status_code}")
                return False
                
        except Exception as e:
            self.logger.error(f"å•çº¿ç¨‹ä¸‹è½½å¼‚å¸¸: {str(e)}")
            return False

def main():
    """ä¸»å‡½æ•° - ä¸‹è½½GFWæ•°æ®"""
    # ä»ä¹‹å‰çš„è„šæœ¬è¾“å‡ºä¸­æå–ä¸‹è½½ä¿¡æ¯
    download_url = "https://data-api.globalforestwatch.org/dataset/gfw_planted_forests/latest/download/gpkg?geostore_id=0c6aea80-150d-866a-030f-c892d7f76757"
    api_key = "81a61ed9-254d-4974-8097-385a346f721b"
    filename = f"gfw_planted_forests_{datetime.now().strftime('%Y%m%d_%H%M%S')}.gpkg"
    
    # è®¾ç½®è¯·æ±‚å¤´
    headers = {
        'x-api-key': api_key,
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    print("ğŸŒ² GFWæ•°æ®å¿«é€Ÿä¸‹è½½å™¨")
    print("=" * 60)
    print(f"ğŸ“ ç›®æ ‡æ–‡ä»¶: {filename}")
    print(f"ğŸ”— ä¸‹è½½é“¾æ¥: {download_url}")
    print("=" * 60)
    
    # åˆ›å»ºä¸‹è½½å™¨å®ä¾‹
    downloader = FastDownloader(
        use_proxy=True,      # ä½¿ç”¨VPNä»£ç†
        proxy_port=7890,     # VPNç«¯å£
        max_workers=8,       # 8ä¸ªçº¿ç¨‹
        chunk_size=10*1024*1024  # æ¯ä¸ªçº¿ç¨‹10MB
    )
    
    # å¼€å§‹ä¸‹è½½
    success = downloader.download_file(download_url, filename, headers, resume=True)
    
    if success:
        file_size = os.path.getsize(filename) / (1024*1024)
        print(f"ğŸ‰ ä¸‹è½½æˆåŠŸ! æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
        print(f"ğŸ“ ä¿å­˜ä½ç½®: {os.path.abspath(filename)}")
    else:
        print("âŒ ä¸‹è½½å¤±è´¥!")
    
    print("=" * 60)

if __name__ == "__main__":
    main()