#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GFWäººå·¥æ—æ•°æ®ä¸‹è½½è„šæœ¬
ç›®çš„ï¼šåŸºäºæŸ¥è¯¢ç»“æœä¸‹è½½æŒ‡å®šåŒºåŸŸçš„GFWäººå·¥æ—æ•°æ®ï¼Œè‡ªåŠ¨åˆ¤æ–­å¹¶ä¸‹è½½å¯ç”¨æ ¼å¼
ä½œè€…ï¼šé”å¤šå® (ruiduobao)
"""

import requests
import json
import os
from datetime import datetime

def load_query_results(json_file):
    """è¯»å–æŸ¥è¯¢ç»“æœJSONæ–‡ä»¶"""
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"âœ… æˆåŠŸè¯»å–æŸ¥è¯¢ç»“æœ: {json_file}")
        return data
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
        return None

def get_dataset_assets(api_key, dataset_id, version="latest"):
    """è·å–æ•°æ®é›†æ”¯æŒçš„èµ„äº§æ ¼å¼"""
    url = f"https://data-api.globalforestwatch.org/dataset/{dataset_id}/{version}/assets"
    headers = {'x-api-key': api_key}
    
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            data = response.json()
            assets = data.get('data', [])
            downloadable_assets = [asset for asset in assets if asset.get('is_downloadable', False)]
            print(f"ğŸ“‹ æ•°æ®é›†æ”¯æŒ {len(downloadable_assets)} ç§å¯ä¸‹è½½æ ¼å¼:")
            
            for asset in downloadable_assets:
                asset_type = asset.get('asset_type', 'Unknown')
                print(f"   - {asset_type}")
                
                # å¦‚æœæ˜¯æ …æ ¼ç“¦ç‰‡é›†ï¼Œæå–gridå’Œpixel_meaningä¿¡æ¯
                if asset_type == 'Raster tile set':
                    asset_uri = asset.get('asset_uri', '')
                    asset_id = asset.get('asset_id', '')
                    print(f"     èµ„äº§ID: {asset_id}")
                    
                    # ä»asset_uriä¸­è§£ægridå’Œpixel_meaning
                    # ä¾‹å¦‚: s3://.../espy-3857/zoom_0/coverage_gradient/geotiff/....tif
                    if asset_uri:
                        uri_parts = asset_uri.split('/')
                        for i, part in enumerate(uri_parts):
                            if part.startswith('zoom_'):
                                grid = part
                                if i + 1 < len(uri_parts):
                                    pixel_meaning = uri_parts[i + 1]
                                    print(f"     ç½‘æ ¼: {grid}, åƒç´ å«ä¹‰: {pixel_meaning}")
                                    # å°†è¿™äº›ä¿¡æ¯å­˜å‚¨åˆ°assetä¸­ä»¥ä¾¿åç»­ä½¿ç”¨
                                    asset['grid'] = grid
                                    asset['pixel_meaning'] = pixel_meaning
                                break
            
            return downloadable_assets
        else:
            print(f"âš ï¸  è·å–èµ„äº§ä¿¡æ¯å¤±è´¥: {response.status_code}")
            return []
    except Exception as e:
        print(f"âŒ è·å–èµ„äº§ä¿¡æ¯å¼‚å¸¸: {str(e)}")
        return []

def get_tiles_info(api_key, asset_id):
    """è·å–æŒ‡å®šèµ„äº§çš„ç“¦ç‰‡ä¿¡æ¯"""
    url = f"https://data-api.globalforestwatch.org/asset/{asset_id}/tiles_info"
    headers = {'x-api-key': api_key}
    
    try:
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            data = response.json()
            tiles = data.get('data', [])
            print(f"ğŸ—‚ï¸  èµ„äº§ {asset_id} åŒ…å« {len(tiles)} ä¸ªç“¦ç‰‡")
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªç“¦ç‰‡çš„ä¿¡æ¯
            for i, tile in enumerate(tiles[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                tile_id = tile.get('tile_id', 'Unknown')
                print(f"   ç“¦ç‰‡ {i+1}: {tile_id}")
            
            if len(tiles) > 3:
                print(f"   ... è¿˜æœ‰ {len(tiles) - 3} ä¸ªç“¦ç‰‡")
            
            return tiles
        else:
            print(f"âš ï¸  è·å–ç“¦ç‰‡ä¿¡æ¯å¤±è´¥: {response.status_code}")
            return []
    except Exception as e:
        print(f"âŒ è·å–ç“¦ç‰‡ä¿¡æ¯å¼‚å¸¸: {str(e)}")
        return []

def download_data(api_key, dataset_id, version, format_type, geostore_id, sql_query, asset_info=None):
    """ä¸‹è½½æŒ‡å®šæ ¼å¼çš„æ•°æ®"""
    base_url = f"https://data-api.globalforestwatch.org/dataset/{dataset_id}/{version}/download"
    headers = {'x-api-key': api_key}
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    try:
        if format_type in ['json', 'csv']:
            # JSON/CSVæ ¼å¼ä½¿ç”¨POSTè¯·æ±‚
            url = f"{base_url}/{format_type}"
            payload = {"sql": sql_query}
            if geostore_id:
                payload["geostore_id"] = geostore_id
            
            print(f"ğŸ“¥ ä¸‹è½½{format_type.upper()}æ ¼å¼...")
            print(f"ğŸ”— ä¸‹è½½URL: {url}")
            print(f"ğŸ“‹ è¯·æ±‚å¤´: {headers}")
            print(f"ğŸ“¦ POSTæ•°æ®: {json.dumps(payload, indent=2, ensure_ascii=False)}")
            
            response = requests.post(url, headers=headers, json=payload, stream=True)
            filename = f"gfw_planted_forests_{timestamp}.{format_type}"
            
        elif format_type in ['shp', 'gpkg']:
            # Shapefile/Geopackageæ ¼å¼ä½¿ç”¨GETè¯·æ±‚
            url = f"{base_url}/{format_type}"
            params = {}
            if geostore_id:
                params["geostore_id"] = geostore_id
                url += f"?geostore_id={geostore_id}"
            
            print(f"ğŸ“¥ ä¸‹è½½{format_type.upper()}æ ¼å¼...")
            print(f"ğŸ”— ä¸‹è½½URL: {url}")
            print(f"ğŸ“‹ è¯·æ±‚å¤´: {headers}")
            if params:
                print(f"ğŸ“¦ GETå‚æ•°: {json.dumps(params, indent=2, ensure_ascii=False)}")
            
            # ç”Ÿæˆcurlå‘½ä»¤ä¾›ç¬¬ä¸‰æ–¹å·¥å…·ä½¿ç”¨
            curl_cmd = f'curl -X GET "{url}"'
            for key, value in headers.items():
                curl_cmd += f' -H "{key}: {value}"'
            print(f"ğŸ’» ç­‰æ•ˆcurlå‘½ä»¤:")
            print(f"   {curl_cmd}")
            print(f"   è¾“å‡ºæ–‡ä»¶: gfw_planted_forests_{timestamp}.{format_type}")
            
            response = requests.get(url, headers=headers, stream=True)
            ext = 'zip' if format_type == 'shp' else format_type
            filename = f"gfw_planted_forests_{timestamp}.{ext}"
            
        elif format_type == 'geotiff':
            # Geotiffæ ¼å¼éœ€è¦ç‰¹æ®Šå¤„ç†
            if not asset_info:
                print("âŒ Geotiffæ ¼å¼éœ€è¦èµ„äº§ä¿¡æ¯")
                return False
            
            print(f"ğŸ“¥ ä¸‹è½½Geotiffæ ¼å¼...")
            print(f"ğŸ—‚ï¸  èµ„äº§ä¿¡æ¯: {asset_info}")
            
            # è·å–ç“¦ç‰‡ä¿¡æ¯
            tiles_info = get_tiles_info(api_key, asset_info['asset_id'])
            if not tiles_info or not tiles_info.get('tiles'):
                print("âŒ æ— æ³•è·å–ç“¦ç‰‡ä¿¡æ¯")
                return False
            
            # é€‰æ‹©ç¬¬ä¸€ä¸ªç“¦ç‰‡è¿›è¡Œä¸‹è½½
            tile_id = tiles_info['tiles'][0]['tile_id']
            grid = asset_info.get('grid', 'zoom_0')
            pixel_meaning = asset_info.get('pixel_meaning', 'coverage_gradient')
            
            url = f"https://data-api.globalforestwatch.org/dataset/{dataset_id}/{version}/assets/{asset_info['asset_id']}/tiles/{tile_id}"
            
            print(f"ğŸ”— ä¸‹è½½URL: {url}")
            print(f"ğŸ“‹ è¯·æ±‚å¤´: {headers}")
            print(f"ğŸ—‚ï¸  ç“¦ç‰‡ID: {tile_id}")
            print(f"ğŸŒ ç½‘æ ¼: {grid}")
            print(f"ğŸ¨ åƒç´ å«ä¹‰: {pixel_meaning}")
            
            # ç”Ÿæˆcurlå‘½ä»¤ä¾›ç¬¬ä¸‰æ–¹å·¥å…·ä½¿ç”¨
            curl_cmd = f'curl -X GET "{url}"'
            for key, value in headers.items():
                curl_cmd += f' -H "{key}: {value}"'
            print(f"ğŸ’» ç­‰æ•ˆcurlå‘½ä»¤:")
            print(f"   {curl_cmd}")
            print(f"   è¾“å‡ºæ–‡ä»¶: gfw_planted_forests_{timestamp}.tif")
            
            response = requests.get(url, headers=headers, stream=True)
            filename = f"gfw_planted_forests_{timestamp}.tif"
            
        else:
            print(f"âš ï¸  ä¸æ”¯æŒçš„æ ¼å¼: {format_type}")
            return False
        
        # æ£€æŸ¥å“åº”çŠ¶æ€
        if response.status_code == 200:
            print(f"âœ… å¼€å§‹ä¸‹è½½æ–‡ä»¶: {filename}")
            
            # è·å–æ–‡ä»¶å¤§å°
            total_size = int(response.headers.get('content-length', 0))
            if total_size > 0:
                print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {total_size / (1024*1024):.2f} MB")
            
            # ä¸‹è½½æ–‡ä»¶å¹¶æ˜¾ç¤ºè¿›åº¦
            downloaded = 0
            with open(filename, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        if total_size > 0:
                            progress = (downloaded / total_size) * 100
                            print(f"\rğŸ“¥ ä¸‹è½½è¿›åº¦: {progress:.1f}% ({downloaded / (1024*1024):.2f}/{total_size / (1024*1024):.2f} MB)", end='', flush=True)
            
            print(f"\nâœ… {format_type.upper()}æ ¼å¼ä¸‹è½½å®Œæˆ: {filename}")
            return True
        else:
            print(f"âŒ {format_type.upper()}ä¸‹è½½å¤±è´¥: {response.status_code} - {response.text[:200]}")
            return False
            
    except Exception as e:
        print(f"âŒ {format_type.upper()}ä¸‹è½½å¼‚å¸¸: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®å‚æ•°
    api_key = "81a61ed9-254d-4974-8097-385a346f721b"
    dataset_id = "gfw_planted_forests"
    version = "latest"
    query_file = r"F:\BaiduSyncdisk\è®ºæ–‡\ä¸œå—äºš10mäººå·¥æ—æå–\ä»£ç \1.æ•°æ®é¢„å¤„ç†\SDPTä¸‹è½½\gfw_planted_forests_query_20250919_165906.json"
    
    print("ğŸŒ² GFWäººå·¥æ—æ•°æ®ä¸‹è½½å™¨")
    print("=" * 50)
    
    # è¯»å–æŸ¥è¯¢ç»“æœ
    query_data = load_query_results(query_file)
    if not query_data:
        return
    
    # æå–geostore_idå’Œæ„å»ºSQLæŸ¥è¯¢
    geostore_id = None
    if query_data.get('data') and len(query_data['data']) > 0:
        geostore_id = query_data['data'][0].get('gfw_geostore_id')
        print(f"ğŸ¯ ä½¿ç”¨Geostore ID: {geostore_id}")
    
    sql_query = f"SELECT * FROM data WHERE gfw_geostore_id = '{geostore_id}'" if geostore_id else "SELECT * FROM data LIMIT 100"
    
    # è·å–å¯ç”¨çš„ä¸‹è½½æ ¼å¼
    assets = get_dataset_assets(api_key, dataset_id, version)
    if not assets:
        print("âš ï¸  æœªæ‰¾åˆ°å¯ä¸‹è½½çš„èµ„äº§æ ¼å¼ï¼Œå°è¯•é»˜è®¤æ ¼å¼...")
        download_formats = ['json', 'csv']  # é»˜è®¤å°è¯•è¿™äº›æ ¼å¼
        asset_mapping = {}
    else:
        # æ ¹æ®èµ„äº§ç±»å‹æ˜ å°„åˆ°ä¸‹è½½æ ¼å¼
        format_mapping = {
            'Geo database table': ['json', 'csv'],
            'Database table': ['json', 'csv'],
            'ESRI Shapefile': ['shp'],
            'Geopackage': ['gpkg'],
            'Raster tile set': ['geotiff']  # æ …æ ¼ç“¦ç‰‡é›†æ”¯æŒgeotiffæ ¼å¼
        }
        
        download_formats = []
        asset_mapping = {}  # å­˜å‚¨æ ¼å¼åˆ°èµ„äº§ä¿¡æ¯çš„æ˜ å°„
        
        for asset in assets:
            asset_type = asset.get('asset_type', '')
            formats = format_mapping.get(asset_type, [])
            download_formats.extend(formats)
            
            # ä¸ºgeotiffæ ¼å¼å­˜å‚¨èµ„äº§ä¿¡æ¯
            if asset_type == 'Raster tile set' and 'geotiff' in formats:
                asset_mapping['geotiff'] = asset
        
        # å»é‡å¹¶ä¼˜å…ˆé€‰æ‹©å¸¸ç”¨æ ¼å¼
        download_formats = list(dict.fromkeys(download_formats))  # ä¿æŒé¡ºåºå»é‡
        if not download_formats:
            download_formats = ['json', 'csv']  # é»˜è®¤æ ¼å¼
    
    print(f"ğŸ“¦ å‡†å¤‡ä¸‹è½½æ ¼å¼: {', '.join(download_formats)}")
    
    # ä¸‹è½½æ•°æ®
    success_count = 0
    for fmt in download_formats:
        print(f"\n{'='*30}")
        # è·å–å¯¹åº”æ ¼å¼çš„èµ„äº§ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        asset_info = asset_mapping.get(fmt, None)
        success = download_data(api_key, dataset_id, version, fmt, geostore_id, sql_query, asset_info)
        if success:
            success_count += 1
    
    print(f"\n{'='*50}")
    print(f"ğŸ‰ ä¸‹è½½å®Œæˆ! æˆåŠŸä¸‹è½½ {success_count}/{len(download_formats)} ç§æ ¼å¼")
    print("=" * 50)

if __name__ == "__main__":
    main()