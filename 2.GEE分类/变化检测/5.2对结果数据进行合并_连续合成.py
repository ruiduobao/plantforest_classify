#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºåŸºå‡†å¹´ä»½å½±åƒå’Œå¤šå¹´å˜åŒ–æ£€æµ‹ç»“æœçš„è¿ç»­å½±åƒåˆå¹¶è„šæœ¬
åŠŸèƒ½ï¼šä»åŸºå‡†å¹´ä»½å¼€å§‹ï¼Œé€å¹´å‘å‰åº”ç”¨å˜åŒ–æ£€æµ‹ç»“æœï¼Œç”Ÿæˆè¿ç»­å¤šå¹´çš„åˆ†ç±»ç»“æœ
æ”¯æŒæ‰¹é‡å¤„ç†GEEå¯¼å‡ºçš„åˆ†å—å˜åŒ–æ£€æµ‹ç»“æœæ–‡ä»¶
ä½œè€…ï¼šé”å¤šå® (ruiduobao)
æ—¥æœŸï¼š2025å¹´1æœˆ
"""

import os
import sys
import time
import logging
from datetime import datetime
import numpy as np
import rasterio
from rasterio import windows
from rasterio.enums import Resampling
from tqdm import tqdm
import gc
import glob
from pathlib import Path

def scan_change_detection_files(input_dir, pattern="*.tif"):
    """
    æ‰«ææŒ‡å®šç›®å½•ä¸‹çš„å˜åŒ–æ£€æµ‹åˆ†å—æ–‡ä»¶
    
    å‚æ•°:
    - input_dir: è¾“å…¥ç›®å½•è·¯å¾„
    - pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼Œé»˜è®¤ä¸º"*.tif"
    
    è¿”å›:
    - æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    input_path = Path(input_dir)
    if not input_path.exists():
        raise FileNotFoundError(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
    
    # æœç´¢æ‰€æœ‰tifæ–‡ä»¶
    tif_files = list(input_path.glob(pattern))
    
    if not tif_files:
        raise FileNotFoundError(f"åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶: {pattern}")
    
    # æŒ‰æ–‡ä»¶åæ’åºï¼Œç¡®ä¿å¤„ç†é¡ºåºä¸€è‡´
    tif_files.sort()
    
    logging.info(f"åœ¨ç›®å½• {input_dir} ä¸­æ‰¾åˆ° {len(tif_files)} ä¸ªå˜åŒ–æ£€æµ‹æ–‡ä»¶")
    for i, file_path in enumerate(tif_files, 1):
        logging.info(f"  {i:2d}. {file_path.name}")
    
    return [str(f) for f in tif_files]

def get_raster_bounds_info(raster_path):
    """
    è·å–æ …æ ¼æ–‡ä»¶çš„è¾¹ç•Œä¿¡æ¯
    
    å‚æ•°:
    - raster_path: æ …æ ¼æ–‡ä»¶è·¯å¾„
    
    è¿”å›:
    - è¾¹ç•Œä¿¡æ¯å­—å…¸
    """
    with rasterio.open(raster_path) as src:
        return {
            'bounds': src.bounds,
            'crs': src.crs,
            'transform': src.transform,
            'width': src.width,
            'height': src.height,
            'res': src.res
        }

def setup_logging(output_dir):
    """
    è®¾ç½®æ—¥å¿—è®°å½•
    """
    log_filename = f"merge_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    log_path = os.path.join(output_dir, log_filename)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_path, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return log_path

def check_raster_compatibility(base_path, change_path):
    """
    æ£€æŸ¥ä¸¤ä¸ªæ …æ ¼æ–‡ä»¶çš„å…¼å®¹æ€§ï¼ˆæŠ•å½±ã€åˆ†è¾¨ç‡ã€èŒƒå›´ç­‰ï¼‰
    """
    with rasterio.open(base_path) as base_src, rasterio.open(change_path) as change_src:
        # æ£€æŸ¥æŠ•å½±ç³»ç»Ÿ
        if base_src.crs != change_src.crs:
            logging.warning(f"æŠ•å½±ç³»ç»Ÿä¸åŒ¹é…: åº•å›¾={base_src.crs}, å˜åŒ–æ£€æµ‹={change_src.crs}")
            return False
        
        # æ£€æŸ¥åˆ†è¾¨ç‡
        if base_src.res != change_src.res:
            logging.warning(f"åˆ†è¾¨ç‡ä¸åŒ¹é…: åº•å›¾={base_src.res}, å˜åŒ–æ£€æµ‹={change_src.res}")
            return False
        
        # æ£€æŸ¥å½±åƒèŒƒå›´
        base_bounds = base_src.bounds
        change_bounds = change_src.bounds
        
        logging.info(f"åº•å›¾èŒƒå›´: {base_bounds}")
        logging.info(f"å˜åŒ–æ£€æµ‹èŒƒå›´: {change_bounds}")
        
        # è®¡ç®—é‡å åŒºåŸŸ
        overlap_left = max(base_bounds.left, change_bounds.left)
        overlap_bottom = max(base_bounds.bottom, change_bounds.bottom)
        overlap_right = min(base_bounds.right, change_bounds.right)
        overlap_top = min(base_bounds.top, change_bounds.top)
        
        if overlap_left >= overlap_right or overlap_bottom >= overlap_top:
            logging.error("ä¸¤ä¸ªå½±åƒæ²¡æœ‰é‡å åŒºåŸŸï¼")
            return False
        
        logging.info(f"é‡å åŒºåŸŸ: left={overlap_left}, bottom={overlap_bottom}, right={overlap_right}, top={overlap_top}")
        return True

def apply_change_patch_to_base(base_path, change_path, base_data_cache=None, base_transform=None):
    """
    å°†å•ä¸ªå˜åŒ–æ£€æµ‹åˆ†å—åº”ç”¨åˆ°åº•å›¾çš„å¯¹åº”åŒºåŸŸ
    
    å‚æ•°:
    - base_path: åº•å›¾æ–‡ä»¶è·¯å¾„
    - change_path: å˜åŒ–æ£€æµ‹åˆ†å—æ–‡ä»¶è·¯å¾„
    - base_data_cache: åº•å›¾æ•°æ®ç¼“å­˜ï¼ˆå¯é€‰ï¼Œç”¨äºå†…å­˜ä¼˜åŒ–ï¼‰
    - base_transform: åº•å›¾çš„åœ°ç†å˜æ¢å‚æ•°
    
    è¿”å›:
    - ä¿®æ”¹çš„åƒç´ ç»Ÿè®¡ä¿¡æ¯
    """
    
    logging.info(f"åº”ç”¨å˜åŒ–æ£€æµ‹åˆ†å—: {os.path.basename(change_path)}")
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    if not os.path.exists(change_path):
        raise FileNotFoundError(f"å˜åŒ–æ£€æµ‹æ–‡ä»¶ä¸å­˜åœ¨: {change_path}")
    
    start_time = time.time()
    
    with rasterio.open(base_path, 'r+') as base_src, rasterio.open(change_path) as change_src:
        
        # æ£€æŸ¥åŸºæœ¬å…¼å®¹æ€§
        if base_src.crs != change_src.crs:
            logging.warning(f"æŠ•å½±ç³»ç»Ÿä¸åŒ¹é…: åº•å›¾={base_src.crs}, å˜åŒ–æ£€æµ‹={change_src.crs}")
        
        # è®¡ç®—å˜åŒ–æ£€æµ‹åˆ†å—åœ¨åº•å›¾ä¸­çš„çª—å£ä½ç½®
        change_bounds = change_src.bounds
        base_window = windows.from_bounds(
            change_bounds.left, change_bounds.bottom,
            change_bounds.right, change_bounds.top,
            base_src.transform
        )
        
        # ç¡®ä¿çª—å£ä¸ºæ•´æ•°å¹¶åœ¨åº•å›¾èŒƒå›´å†…
        base_window = windows.Window(
            max(0, int(round(base_window.col_off))),
            max(0, int(round(base_window.row_off))),
            min(base_src.width - max(0, int(round(base_window.col_off))), int(round(base_window.width))),
            min(base_src.height - max(0, int(round(base_window.row_off))), int(round(base_window.height)))
        )
        
        if base_window.width <= 0 or base_window.height <= 0:
            logging.warning(f"å˜åŒ–æ£€æµ‹åˆ†å— {os.path.basename(change_path)} ä¸åº•å›¾æ²¡æœ‰é‡å åŒºåŸŸï¼Œè·³è¿‡")
            return {'applied': False, 'reason': 'no_overlap', 'changed_pixels': 0}
        
        logging.info(f"åº”ç”¨çª—å£: col={base_window.col_off}, row={base_window.row_off}, "
                    f"width={base_window.width}, height={base_window.height}")
        
        # è¯»å–åº•å›¾å¯¹åº”åŒºåŸŸçš„æ•°æ®
        base_data = base_src.read(1, window=base_window)
        
        # è¯»å–å˜åŒ–æ£€æµ‹æ•°æ®ï¼Œé‡é‡‡æ ·åˆ°ä¸åº•å›¾çª—å£åŒ¹é…çš„å¤§å°
        change_data = change_src.read(1, out_shape=(base_window.height, base_window.width))
        
        # ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´
        if base_data.dtype != change_data.dtype:
            change_data = change_data.astype(base_data.dtype)
        
        # åº”ç”¨å˜åŒ–ï¼šå˜åŒ–æ£€æµ‹é0å€¼è¦†ç›–åº•å›¾
        change_mask = change_data != 0
        original_data = base_data.copy()
        base_data[change_mask] = change_data[change_mask]
        
        # å°†ä¿®æ”¹åçš„æ•°æ®å†™å›åº•å›¾
        base_src.write(base_data, 1, window=base_window)
        
        # ç»Ÿè®¡ä¿®æ”¹çš„åƒç´ æ•°
        changed_pixels = np.sum(change_mask)
        
        # å¤„ç†å®Œæˆç»Ÿè®¡
        end_time = time.time()
        processing_time = end_time - start_time
        
        stats = {
            'applied': True,
            'file_name': os.path.basename(change_path),
            'processing_time': processing_time,
            'changed_pixels': changed_pixels,
            'total_patch_pixels': base_data.size,
            'change_percentage': (changed_pixels / base_data.size) * 100 if base_data.size > 0 else 0
        }
        
        logging.info(f"å®Œæˆåº”ç”¨ {os.path.basename(change_path)}: "
                    f"ä¿®æ”¹åƒç´  {changed_pixels:,}/{base_data.size:,} "
                    f"({stats['change_percentage']:.2f}%), è€—æ—¶ {processing_time:.2f}ç§’")
        
        return stats

def batch_apply_changes_to_base_image_sequential(base_image_path, change_detection_base_dir, 
                                              output_dir, base_year, start_year, end_year,
                                              file_pattern_template="*.tif"):
    """
    è¿ç»­å¤šå¹´æ‰¹é‡å°†å˜åŒ–æ£€æµ‹åˆ†å—åº”ç”¨åˆ°åº•å›¾ä¸Šï¼Œç”Ÿæˆå¤šå¹´è¿ç»­åˆ†ç±»ç»“æœ
    
    å‚æ•°:
    - base_image_path: åŸºå‡†å¹´ä»½åº•å›¾æ–‡ä»¶è·¯å¾„
    - change_detection_base_dir: å˜åŒ–æ£€æµ‹åˆ†å—æ–‡ä»¶æ ¹ç›®å½•ï¼ˆåŒ…å«å„å¹´ä»½å­ç›®å½•ï¼‰
    - output_dir: è¾“å‡ºç›®å½•
    - base_year: åŸºå‡†å¹´ä»½ï¼ˆå¦‚2024ï¼‰
    - start_year: å¼€å§‹å¤„ç†å¹´ä»½ï¼ˆå¦‚2023ï¼‰
    - end_year: ç»“æŸå¹´ä»½ï¼ˆå¦‚2017ï¼‰
    - file_pattern_template: æ–‡ä»¶åŒ¹é…æ¨¡å¼æ¨¡æ¿ï¼ŒåŒ¹é…æ¯ä¸ªå¹´ä»½æ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶
    
    è¿”å›:
    - æ‰€æœ‰å¹´ä»½çš„å¤„ç†ç»Ÿè®¡ä¿¡æ¯
    """
    
    # è®¾ç½®æ—¥å¿—
    os.makedirs(output_dir, exist_ok=True)
    logger = setup_logging(output_dir)
    
    logging.info("="*80)
    logging.info("å¼€å§‹è¿ç»­å¤šå¹´å˜åŒ–æ£€æµ‹åˆ†å—æ‰¹é‡åˆå¹¶")
    logging.info(f"åŸºå‡†åº•å›¾: {base_image_path} ({base_year}å¹´)")
    logging.info(f"å˜åŒ–æ£€æµ‹æ ¹ç›®å½•: {change_detection_base_dir}")
    logging.info(f"è¾“å‡ºç›®å½•: {output_dir}")
    logging.info(f"å¤„ç†å¹´ä»½èŒƒå›´: {start_year} â†’ {end_year}")
    logging.info(f"æ–‡ä»¶åŒ¹é…æ¨¡å¼: {file_pattern_template}")
    logging.info("="*80)
    
    # æ£€æŸ¥åŸºå‡†åº•å›¾æ–‡ä»¶
    if not os.path.exists(base_image_path):
        raise FileNotFoundError(f"åŸºå‡†åº•å›¾æ–‡ä»¶ä¸å­˜åœ¨: {base_image_path}")
    
    # ç”Ÿæˆå¹´ä»½åˆ—è¡¨ï¼ˆä»start_yearåˆ°end_yearï¼Œé€’å‡ï¼‰
    years_to_process = list(range(start_year, end_year - 1, -1))
    logging.info(f"å°†æŒ‰é¡ºåºå¤„ç†å¹´ä»½: {years_to_process}")
    
    # æ€»ä½“ç»Ÿè®¡ä¿¡æ¯
    all_years_stats = {
        'base_year': base_year,
        'processed_years': [],
        'failed_years': [],
        'total_processing_time': 0,
        'yearly_results': {}
    }
    
    # å½“å‰å·¥ä½œåº•å›¾è·¯å¾„ï¼ˆåˆå§‹ä¸ºåŸºå‡†åº•å›¾ï¼‰
    current_base_path = base_image_path
    
    start_time = time.time()
    
    try:
        for year in years_to_process:
            logging.info(f"\n{'='*60}")
            logging.info(f"å¼€å§‹å¤„ç† {year} å¹´å˜åŒ–æ£€æµ‹")
            logging.info(f"{'='*60}")
            
            # æ„å»ºå½“å‰å¹´ä»½çš„å˜åŒ–æ£€æµ‹ç›®å½•å’Œæ–‡ä»¶æ¨¡å¼
            year_change_dir = os.path.join(change_detection_base_dir, str(year))
            year_file_pattern = file_pattern_template  # ç›´æ¥ä½¿ç”¨æ¨¡æ¿ï¼Œä¸éœ€è¦æ ¼å¼åŒ–å¹´ä»½
            
            # æ£€æŸ¥å¹´ä»½ç›®å½•æ˜¯å¦å­˜åœ¨
            if not os.path.exists(year_change_dir):
                logging.warning(f"å¹´ä»½ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡: {year_change_dir}")
                all_years_stats['failed_years'].append({
                    'year': year,
                    'reason': 'directory_not_found',
                    'path': year_change_dir
                })
                continue
            
            # ç”Ÿæˆå½“å‰å¹´ä»½çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
            output_filename = f"merged_zone5_{year}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.tif"
            year_output_path = os.path.join(output_dir, output_filename)
            
            try:
                # åº”ç”¨å½“å‰å¹´ä»½çš„å˜åŒ–æ£€æµ‹
                year_result = batch_apply_changes_to_base_image(
                    base_image_path=current_base_path,
                    change_detection_dir=year_change_dir,
                    output_path=year_output_path,
                    file_pattern=year_file_pattern
                )
                
                # è®°å½•æˆåŠŸå¤„ç†çš„å¹´ä»½
                all_years_stats['processed_years'].append(year)
                all_years_stats['yearly_results'][year] = {
                    'result': year_result,
                    'output_file': year_output_path,
                    'input_base': current_base_path
                }
                
                # æ›´æ–°å½“å‰å·¥ä½œåº•å›¾ä¸ºåˆšç”Ÿæˆçš„ç»“æœ
                current_base_path = year_output_path
                
                logging.info(f"âœ… {year}å¹´å¤„ç†å®Œæˆ")
                logging.info(f"   è¾“å‡ºæ–‡ä»¶: {year_output_path}")
                logging.info(f"   æˆåŠŸå¤„ç†: {year_result['processed_files']} ä¸ªæ–‡ä»¶")
                logging.info(f"   å˜åŒ–æ¯”ä¾‹: {year_result['overall_change_percentage']:.2f}%")
                
            except Exception as e:
                logging.error(f"âŒ {year}å¹´å¤„ç†å¤±è´¥: {str(e)}")
                all_years_stats['failed_years'].append({
                    'year': year,
                    'reason': 'processing_error',
                    'error': str(e)
                })
                # å¤„ç†å¤±è´¥æ—¶ä¸æ›´æ–°current_base_pathï¼Œç»§ç»­ä½¿ç”¨ä¸Šä¸€ä¸ªæˆåŠŸçš„ç»“æœ
                continue
        
        # è®¡ç®—æ€»ä½“å¤„ç†æ—¶é—´
        total_time = time.time() - start_time
        all_years_stats['total_processing_time'] = total_time
        
        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        logging.info("\n" + "="*80)
        logging.info("è¿ç»­å¤šå¹´å˜åŒ–æ£€æµ‹åˆå¹¶å®Œæˆç»Ÿè®¡:")
        logging.info(f"åŸºå‡†å¹´ä»½: {base_year}")
        logging.info(f"æˆåŠŸå¤„ç†å¹´ä»½: {all_years_stats['processed_years']}")
        logging.info(f"å¤±è´¥å¹´ä»½æ•°: {len(all_years_stats['failed_years'])}")
        logging.info(f"æ€»å¤„ç†æ—¶é—´: {total_time:.2f}ç§’")
        
        if all_years_stats['failed_years']:
            logging.info("\nå¤±è´¥å¹´ä»½è¯¦æƒ…:")
            for failed in all_years_stats['failed_years']:
                logging.info(f"  - {failed['year']}å¹´: {failed['reason']}")
        
        logging.info("="*80)
        
        # ä¿å­˜æ€»ä½“ç»Ÿè®¡ç»“æœ
        stats_file = os.path.join(output_dir, f"sequential_merge_stats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        try:
            import json
            
            def convert_numpy_types(obj):
                """é€’å½’è½¬æ¢numpyæ•°æ®ç±»å‹å’Œrasterioå¯¹è±¡ä¸ºPythonåŸç”Ÿç±»å‹"""
                if isinstance(obj, dict):
                    return {key: convert_numpy_types(value) for key, value in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy_types(item) for item in obj]
                elif isinstance(obj, np.integer):
                    return int(obj)
                elif isinstance(obj, np.floating):
                    return float(obj)
                elif isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif hasattr(obj, 'to_string'):  # rasterio CRSå¯¹è±¡
                    return obj.to_string()
                elif hasattr(obj, '__dict__'):  # å…¶ä»–å¤æ‚å¯¹è±¡è½¬ä¸ºå­—ç¬¦ä¸²
                    return str(obj)
                else:
                    return obj
            
            with open(stats_file, 'w', encoding='utf-8') as f:
                serializable_stats = convert_numpy_types(all_years_stats.copy())
                json.dump(serializable_stats, f, ensure_ascii=False, indent=2)
            logging.info(f"æ€»ä½“ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ°: {stats_file}")
        except Exception as e:
            logging.warning(f"ä¿å­˜æ€»ä½“ç»Ÿè®¡æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        return all_years_stats
        
    except Exception as e:
        logging.error(f"è¿ç»­å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}")
        raise e

def batch_apply_changes_to_base_image(base_image_path, change_detection_dir, output_path, 
                                    file_pattern="*.tif"):
    """
    æ‰¹é‡å°†å˜åŒ–æ£€æµ‹åˆ†å—åº”ç”¨åˆ°åº•å›¾ä¸Šï¼Œè¾“å‡ºä¸€å¼ å®Œæ•´çš„ä¿®æ”¹ååº•å›¾
    
    å‚æ•°:
    - base_image_path: 2024å¹´åº•å›¾æ–‡ä»¶è·¯å¾„
    - change_detection_dir: å˜åŒ–æ£€æµ‹åˆ†å—æ–‡ä»¶æ‰€åœ¨ç›®å½•
    - output_path: è¾“å‡ºä¿®æ”¹åçš„å®Œæ•´åº•å›¾è·¯å¾„
    - file_pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼Œé»˜è®¤ä¸º"*.tif"
    
    è¿”å›:
    - æ‰¹é‡å¤„ç†ç»Ÿè®¡ä¿¡æ¯
    """
    
    # è®¾ç½®æ—¥å¿—
    output_dir = os.path.dirname(output_path)
    logger = setup_logging(output_dir)
    
    logging.info("="*80)
    logging.info("å¼€å§‹æ‰¹é‡åº”ç”¨å˜åŒ–æ£€æµ‹åˆ†å—åˆ°åº•å›¾")
    logging.info(f"åº•å›¾è·¯å¾„: {base_image_path}")
    logging.info(f"å˜åŒ–æ£€æµ‹ç›®å½•: {change_detection_dir}")
    logging.info(f"è¾“å‡ºè·¯å¾„: {output_path}")
    logging.info(f"æ–‡ä»¶åŒ¹é…æ¨¡å¼: {file_pattern}")
    logging.info("="*80)
    
    # æ£€æŸ¥åº•å›¾æ–‡ä»¶
    if not os.path.exists(base_image_path):
        raise FileNotFoundError(f"åº•å›¾æ–‡ä»¶ä¸å­˜åœ¨: {base_image_path}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # æ‰«æå˜åŒ–æ£€æµ‹æ–‡ä»¶
    change_files = scan_change_detection_files(change_detection_dir, file_pattern)
    
    if not change_files:
        logging.warning(f"åœ¨ç›®å½• {change_detection_dir} ä¸­æœªæ‰¾åˆ°åŒ¹é… {file_pattern} çš„æ–‡ä»¶")
        return {'success': False, 'message': 'No files found'}
    
    logging.info(f"æ‰¾åˆ° {len(change_files)} ä¸ªå˜åŒ–æ£€æµ‹åˆ†å—æ–‡ä»¶")
    
    # å¤åˆ¶åº•å›¾ä½œä¸ºå·¥ä½œå‰¯æœ¬
    import shutil
    temp_base_path = output_path.replace('.tif', '_temp.tif')
    
    try:
        # å¤åˆ¶åº•å›¾åˆ°ä¸´æ—¶æ–‡ä»¶
        logging.info("å¤åˆ¶åº•å›¾åˆ°ä¸´æ—¶å·¥ä½œæ–‡ä»¶...")
        shutil.copy2(base_image_path, temp_base_path)
        
        # æ‰¹é‡å¤„ç†ç»Ÿè®¡
        batch_stats = {
            'total_files': len(change_files),
            'processed_files': 0,
            'failed_files': 0,
            'skipped_files': 0,
            'total_processing_time': 0,
            'total_changed_pixels': 0,
            'file_results': [],
            'failed_files_list': [],
            'skipped_files_list': []
        }
        
        start_time = time.time()
        
        # é€ä¸ªåº”ç”¨å˜åŒ–æ£€æµ‹åˆ†å—
        for i, change_file in enumerate(change_files, 1):
            try:
                logging.info(f"\nå¤„ç†è¿›åº¦: {i}/{len(change_files)} - {os.path.basename(change_file)}")
                
                # åº”ç”¨å˜åŒ–æ£€æµ‹åˆ†å—åˆ°åº•å›¾
                result = apply_change_patch_to_base(temp_base_path, change_file)
                
                if result['applied']:
                    batch_stats['processed_files'] += 1
                    batch_stats['total_processing_time'] += result['processing_time']
                    batch_stats['total_changed_pixels'] += result['changed_pixels']
                    batch_stats['file_results'].append(result)
                    
                    logging.info(f"âœ“ æˆåŠŸåº”ç”¨: {result['file_name']}, "
                               f"ä¿®æ”¹åƒç´ : {result['changed_pixels']:,}")
                else:
                    batch_stats['skipped_files'] += 1
                    batch_stats['skipped_files_list'].append({
                        'file': change_file,
                        'reason': result.get('reason', 'unknown')
                    })
                    logging.warning(f"è·³è¿‡æ–‡ä»¶: {os.path.basename(change_file)} - {result.get('reason', 'unknown')}")
                
            except Exception as e:
                batch_stats['failed_files'] += 1
                batch_stats['failed_files_list'].append({
                    'file': change_file,
                    'error': str(e)
                })
                logging.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {os.path.basename(change_file)}: {str(e)}")
                continue
        
        # å°†ä¸´æ—¶æ–‡ä»¶é‡å‘½åä¸ºæœ€ç»ˆè¾“å‡ºæ–‡ä»¶
        if os.path.exists(output_path):
            os.remove(output_path)
        os.rename(temp_base_path, output_path)
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_time = time.time() - start_time
        batch_stats['total_batch_time'] = total_time
        
        # è®¡ç®—æ•´ä½“å˜åŒ–æ¯”ä¾‹
        with rasterio.open(output_path) as src:
            total_pixels = src.width * src.height
        batch_stats['overall_change_percentage'] = (batch_stats['total_changed_pixels'] / total_pixels) * 100 if total_pixels > 0 else 0
        
        # è·å–è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
        output_info = get_raster_bounds_info(output_path)
        batch_stats['output_file_info'] = output_info
        
        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        logging.info("\n" + "="*80)
        logging.info("æ‰¹é‡åº”ç”¨å˜åŒ–æ£€æµ‹å®Œæˆç»Ÿè®¡:")
        logging.info(f"æ€»æ–‡ä»¶æ•°: {batch_stats['total_files']}")
        logging.info(f"æˆåŠŸå¤„ç†: {batch_stats['processed_files']}")
        logging.info(f"è·³è¿‡æ–‡ä»¶: {batch_stats['skipped_files']}")
        logging.info(f"å¤±è´¥æ–‡ä»¶: {batch_stats['failed_files']}")
        logging.info(f"æ€»å¤„ç†æ—¶é—´: {batch_stats['total_batch_time']:.2f}ç§’")
        logging.info(f"å¹³å‡å¤„ç†æ—¶é—´: {batch_stats['total_processing_time']/max(1, batch_stats['processed_files']):.2f}ç§’/æ–‡ä»¶")
        logging.info(f"æ€»ä¿®æ”¹åƒç´ : {batch_stats['total_changed_pixels']:,}")
        logging.info(f"æ•´ä½“å˜åŒ–æ¯”ä¾‹: {batch_stats['overall_change_percentage']:.2f}%")
        logging.info(f"è¾“å‡ºæ–‡ä»¶: {output_path}")
        
        if batch_stats['failed_files_list']:
            logging.info("\nå¤±è´¥æ–‡ä»¶åˆ—è¡¨:")
            for failed in batch_stats['failed_files_list']:
                logging.info(f"  - {os.path.basename(failed['file'])}: {failed['error']}")
        
        if batch_stats['skipped_files_list']:
            logging.info("\nè·³è¿‡æ–‡ä»¶åˆ—è¡¨:")
            for skipped in batch_stats['skipped_files_list']:
                logging.info(f"  - {os.path.basename(skipped['file'])}: {skipped['reason']}")
        
        logging.info("="*80)
        
        # ä¿å­˜ç»Ÿè®¡ç»“æœåˆ°JSONæ–‡ä»¶
        stats_file = os.path.join(output_dir, f"batch_apply_stats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        try:
            import json
            
            def convert_numpy_types(obj):
                """é€’å½’è½¬æ¢numpyæ•°æ®ç±»å‹å’Œrasterioå¯¹è±¡ä¸ºPythonåŸç”Ÿç±»å‹"""
                if isinstance(obj, dict):
                    return {key: convert_numpy_types(value) for key, value in obj.items()}
                elif isinstance(obj, list):
                    return [convert_numpy_types(item) for item in obj]
                elif isinstance(obj, np.integer):
                    return int(obj)
                elif isinstance(obj, np.floating):
                    return float(obj)
                elif isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif hasattr(obj, 'to_string'):  # rasterio CRSå¯¹è±¡
                    return obj.to_string()
                elif hasattr(obj, '__dict__'):  # å…¶ä»–å¤æ‚å¯¹è±¡è½¬ä¸ºå­—ç¬¦ä¸²
                    return str(obj)
                else:
                    return obj
            
            with open(stats_file, 'w', encoding='utf-8') as f:
                # è½¬æ¢ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
                serializable_stats = convert_numpy_types(batch_stats.copy())
                for result in serializable_stats['file_results']:
                    if 'processing_time' in result:
                        result['processing_time'] = round(result['processing_time'], 2)
                
                json.dump(serializable_stats, f, ensure_ascii=False, indent=2)
            logging.info(f"ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ°: {stats_file}")
        except Exception as e:
            logging.warning(f"ä¿å­˜ç»Ÿè®¡æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        return batch_stats
        
    except Exception as e:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_base_path):
            try:
                os.remove(temp_base_path)
            except:
                pass
        
        logging.error(f"æ‰¹é‡å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        raise e

# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    # ==================== è¿ç»­å¤šå¹´å¤„ç†é…ç½®å‚æ•° ====================
    # åŸºå‡†å¹´ä»½åº•å›¾è·¯å¾„ï¼ˆ2024å¹´åˆ†ç±»ç»“æœï¼‰
    BASE_IMAGE_PATH = r"D:\åœ°ç†æ‰€\è®ºæ–‡\ä¸œå—äºš10mäººå·¥æ—æå–\æ•°æ®\ç¬¬äºŒæ¬¡åˆ†ç±»\merged_zone5_2019_20251024_160615.tif"
    
    # å˜åŒ–æ£€æµ‹æ–‡ä»¶æ ¹ç›®å½•ï¼ˆåŒ…å«å„å¹´ä»½å­ç›®å½•ï¼‰
    CHANGE_DETECTION_BASE_DIR = r"K:\åœ°ç†æ‰€\è®ºæ–‡\ä¸œå—äºš10mäººå·¥æ—æå–\æ•°æ®\GEEåˆ†ç±»\ç¬¬äºŒæ¬¡å˜åŒ–æ£€æµ‹æ–¹æ³•åˆ†ç±»\åŸå§‹GEEå¯¼å‡ºå½±åƒ"
    
    # è¾“å‡ºç›®å½•
    OUTPUT_DIR = r"D:\åœ°ç†æ‰€\è®ºæ–‡\ä¸œå—äºš10mäººå·¥æ—æå–\æ•°æ®\ç¬¬äºŒæ¬¡åˆ†ç±»"
    
    # å¹´ä»½æ§åˆ¶å‚æ•°
    BASE_YEAR = 2019       # åŸºå‡†å¹´ä»½
    START_YEAR = 2018       # å¼€å§‹å¤„ç†å¹´ä»½
    END_YEAR = 2017         # ç»“æŸå¹´ä»½
    
    # æ–‡ä»¶åŒ¹é…æ¨¡å¼æ¨¡æ¿ï¼ˆåŒ¹é…è¯¥å¹´ä»½æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰tifæ–‡ä»¶ï¼‰
    FILE_PATTERN_TEMPLATE = "*.tif"
    
    print("="*80)
    print("GEEå˜åŒ–æ£€æµ‹è¿ç»­å¤šå¹´æ‰¹é‡åˆå¹¶å·¥å…·")
    print("åŠŸèƒ½ï¼šåŸºäºåŸºå‡†å¹´ä»½å½±åƒï¼Œè¿ç»­åº”ç”¨å¤šå¹´å˜åŒ–æ£€æµ‹ç»“æœ")
    print("="*80)
    print(f"åŸºå‡†åº•å›¾: {BASE_IMAGE_PATH} ({BASE_YEAR}å¹´)")
    print(f"å˜åŒ–æ£€æµ‹æ ¹ç›®å½•: {CHANGE_DETECTION_BASE_DIR}")
    print(f"è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print(f"å¤„ç†å¹´ä»½èŒƒå›´: {START_YEAR} â†’ {END_YEAR}")
    print(f"æ–‡ä»¶åŒ¹é…æ¨¡å¼: {FILE_PATTERN_TEMPLATE}")
    print("="*80)
    
    try:
        # æ‰§è¡Œè¿ç»­å¤šå¹´å¤„ç†
        results = batch_apply_changes_to_base_image_sequential(
            base_image_path=BASE_IMAGE_PATH,
            change_detection_base_dir=CHANGE_DETECTION_BASE_DIR,
            output_dir=OUTPUT_DIR,
            base_year=BASE_YEAR,
            start_year=START_YEAR,
            end_year=END_YEAR,
            file_pattern_template=FILE_PATTERN_TEMPLATE
        )
        
        print("\n" + "="*80)
        print("è¿ç»­å¤šå¹´å¤„ç†å®Œæˆæ‘˜è¦:")
        print(f"åŸºå‡†å¹´ä»½: {results['base_year']}")
        print(f"æˆåŠŸå¤„ç†å¹´ä»½: {results['processed_years']}")
        print(f"å¤±è´¥å¹´ä»½æ•°: {len(results['failed_years'])}")
        print(f"æ€»è€—æ—¶: {results['total_processing_time']:.2f}ç§’")
        print("="*80)
        
        if results['processed_years']:
            print(f"\nâœ… æˆåŠŸå¤„ç† {len(results['processed_years'])} ä¸ªå¹´ä»½")
            print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
            for year in results['processed_years']:
                output_file = results['yearly_results'][year]['output_file']
                change_pct = results['yearly_results'][year]['result']['overall_change_percentage']
                print(f"   {year}å¹´: {os.path.basename(output_file)} (å˜åŒ–æ¯”ä¾‹: {change_pct:.2f}%)")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
        else:
            print("\nâŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•å¹´ä»½ï¼Œè¯·æ£€æŸ¥è¾“å…¥å‚æ•°å’Œæ–‡ä»¶è·¯å¾„")
            
        if results['failed_years']:
            print(f"\nâš ï¸  å¤±è´¥å¹´ä»½:")
            for failed in results['failed_years']:
                print(f"   {failed['year']}å¹´: {failed['reason']}")
        
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()